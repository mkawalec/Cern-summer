#! /usr/bin/env python

"""\
%prog --datadir DATADIR [--ipoldir IPOLDIR] --weights OBSFILE [--runsfile RUNSFILE]

%prog --refdir REFDIR --ipoldir IPOLDIR --weights OBSFILE [--runsfile RUNSFILE]

Minimise a goodness of fit (GoF) measure using pre-built MC-interpolations from
IPOLDIR against reference data in REFDIR. The MC-interpolations must be created
with prof-interpolate before running %prog.

If only the DATADIR variable is used to specify input file locations, it is
assumed that the saved interpolations are to be found in DATADIR/ipol, and that
the reference data is in DATADIR/ref. The --refdir and --ipoldir switches can be
used to specify the information explicitly or to override one of the guesses
made using the --datadir value.

The same format of observable weights file (and indeed same file!) as used for
prof-interpolate can be used to specify the observable or bin/range-wise weights
which will enter into the GoF calculation. However, it is of course necessary
that the bins for which weights are requested exist in the stored
interpolations: hence the observables specified at this stage should be a subset
of those used for prof-interpolate. To build output histograms but not include
an observable in the optimisation measure, use a weight of 0.

The RUNSFILE is used to restrict the run combinations for which optimisations
will be calculated. As for the observables specified in the weights file,
interpolations must exist for the requested run combinations. If unspecified, it
will be assumed that a file called runcombs.dat exists and is to be used.

TODO:
  * read in histogram titles
  * check result is in-/outside limits
  * use limits dynamically determined from runcomb
  * threading?? Just use prof-batchtune
"""

import sys, os
import professor.user as prof

from professor.tools import shell as shell
ipshell = shell.usePrettyTraceback()
shell.setProcessName("prof-tune")


## Set up signal handling
import signal
global RECVD_KILL_SIGNAL
RECVD_KILL_SIGNAL = None
def handleKillSignal(signum, frame):
    """
    Declare us as having been signalled, and return to default handling
    behaviour.
    """
    prof.log.critical("Signal handler called with signal " + str(signum))
    prof.log.critical("Waiting for this minimization to finish...")
    global RECVD_KILL_SIGNAL
    RECVD_KILL_SIGNAL = signum
    signal.signal(signum, signal.SIG_DFL)
## Signals to handle
signal.signal(signal.SIGTERM, handleKillSignal);
signal.signal(signal.SIGHUP,  handleKillSignal);
signal.signal(signal.SIGINT,  handleKillSignal);
signal.signal(signal.SIGUSR2, handleKillSignal);


## Build command-line options parser
import optparse
parser = optparse.OptionParser(usage=__doc__, version=prof.version)

## Add standard Prof options
prof.addDataCLOptions(parser, mc=True, ref=True, ipol=True, scan=False)
prof.addRunCombsCLOptions(parser)
prof.addIpolCLOptions(parser)
prof.addOutputCLOptions(parser)

## Tuning options
group = optparse.OptionGroup(parser, "Tuning")
group.add_option("--no-ipolhistos", dest="SAVEIPOLHISTOS",
                 action="store_false", default=True,
                 help="Switch off interpolation histogram storing.")
group.add_option("--no-params", dest="SAVEPARAMS",
                 action="store_false", default=True,
                 help="Switch off creating parameter files with tune results.")
group.add_option("--offset", "--runnum-offset", dest="IRUNOFFSET", metavar="N", default=0, type=int,
                 help="Offset the runcomb variation index by the given value [default: %default]")
parser.add_option_group(group)

mingroup = optparse.OptionGroup(parser, "Minimizer")
mingroup.add_option("--minimizer", choices=("pyminuit", "scipy"),
                    dest="MINIMIZER", default="pyminuit",
                    help="Select the minimizer to use (pyminuit|scipy) [default: %default]")
# TODO: Move to a single --errors=none|migrad|minos option
mingroup.add_option("--minos", dest="USEMINOS", action="store_true",
                    default=False, help="When using Minuit, use MINOS to estimate the "
                    "parameter errors [default: off]")
mingroup.add_option("--print-minuit", dest="PRINTMINUIT", type="choice",
                    choices=("0","1","2","3"), metavar="N", default="0",
                    help="When using Minuit, set printMode to the given"
                         " value. [default: %default]")
mingroup.add_option("--limits", dest="LIMITS", default=None, metavar="FILE",
                    help="File with parameter limits for Minuit. E.g. the"
                         " file used to create the MC sample points.")
mingroup.add_option("--spmethods", "--start-points", metavar="FOO,BAR",
                    dest="STARTPOINTMETHODS", default="center",
                    help="Comma separated list with minimisation starting"
                    " point methods. [default: %default]")
mingroup.add_option("--manual-sp", "--manual-startpoint",
                    dest="MANUALSTARTPOINT", metavar="FOO=N,BAR=M",
                    help="Comma separated list of parameter name - value"
                         " pairs to be used as manual startpoints when"
                         " spmethod 'manual' is selected. Name and value are"
                         " separated by an equals sign ('='), e.g."
                         " PARJ(21)=1.2,PARJ(22)=2.4 . Unspecified parameters"
                         " are chosen randomly.")
mingroup.add_option("--fixed-parameters", dest="FIXEDPARAMETERS",
                    metavar="FOO=N,BAR=M",
                    help="Comma separated list of parameter name - value"
                         " pairs with parameter values to be fixed during"
                         " minimization. Format is the same as with"
                         " '--manual-startpoint', e.g."
                         " PARJ(21)=1.2,PARJ(22)=2.4 . NB: Only supported by"
                         " pyminuit!")
mingroup.add_option("--eigentunes", dest="EIGENTUNES",
                    default=False, action="store_true",
                    help="Make eigentunes using the parameter covariance matrix in the vicinity of the central "
                    "tune to construct parameter eigenvectors which minimise parameter correlations. The "
                    "eigentunes are then the deviations along these lines which produce a fixed deviation in the GoF.")
mingroup.add_option("--eigentunes-dgof", dest="EIGENTUNES_DELTA_GOF", metavar="DGOF", default="1",
                    help="The deviation from the minimum GoF used to define the extent of "
                    "eigentune deviation. For a Pearson chi2-distributed GoF measure, Delta(GoF)=1 "
                    "corresponds to a 1 sigma deviation. Specifying the quantity with an x or % suffix "
                    "will be interpreted as a multiplier on or a percentage of the minimum GoF value, "
                    "motivated by the idea that if the lowest GoF is *not* 1, then the Delta(GoF) should "
                    "be of a similar value to it, rather than a fixed deviation like 1. Make of that what "
                    "you may...  Note that the Professor chi2 is not explicitly designed to have a "
                    "chi2-distribution -- YMMV! (default = %default)")
parser.add_option_group(mingroup)

## Add standard logging control
prof.addLoggingCLOptions(parser, logoswitch=True)

## Parse arguments
opts, args = parser.parse_args()

## Correct argument type on Minuit log level (optparse is not quite general enough)
opts.PRINTMINUIT = int(opts.PRINTMINUIT)

## Set up logging level and print initial messages
prof.log.setPriority(opts)
if opts.SHOW_LOGO:
    prof.writeLogo()
prof.writeGuideLine()

## Check that Delta(GoF) is sane
if opts.EIGENTUNES_DELTA_GOF <= 0:
    prof.log.error("--eigentunes-dgof argument must have a positive value... exiting")
    sys.exit(5)

## Test paths
try:
    ## Test if we can read input ipols and ref data
    dirs_ok = True
    paths = prof.DataProxy.getPathsFromCLOptions(opts)
    ipoldir = paths["ipol"]
    if not ipoldir:
        prof.log.error("No interpolation directory given: Use the --datadir or --ipoldir option!")
        dirs_ok = False
    refdir = paths["ref"]
    if not refdir:
        prof.log.error("No reference data directory given: Use the --datadir or --refdir option!")
        dirs_ok = False
    if not dirs_ok:
        sys.exit(1)

    ## Ensure that we can write to output directories
    OUTDIR = paths["outdir"]
    if not OUTDIR:
        prof.log.error("No output directory given: Use the --datadir or --outdir option!")
        sys.exit(1)
    ## Tune data dir
    TUNEOUTDIR = os.path.join(OUTDIR, "tunes")
    prof.log.debug("Using %s for tune param & pickle file storage" % TUNEOUTDIR)
    prof.io.makeDir(TUNEOUTDIR)
except Exception, e:
    prof.log.error("Error: %s" % e)
    sys.exit(1)


## Get data proxy
try:
    ## Get a DataProxy object (core object for tuning data)
    dataproxy = prof.DataProxy.mkFromCLOptions(opts)
except Exception, e:
    prof.log.error("Error: %s" % e)
    sys.exit(1)


## Get the specified interpolation class. We're only interested in the order
## of the polynomial to construct the file name of the ipol pickles. This is
## not necessarily the exact interpolation method used. I.e. IpolCls will
## always refer to the pure-Python implementation but the pickled files
## might contain the Weave version.
try:
    IpolCls = prof.getInterpolationClass(opts.IPOLMETHOD, False)
    prof.log.info("Using %s polynomial for interpolation." % IpolCls.method)
except Exception, e:
    prof.log.error("Problem getting interpolation method: %s" % e)
    prof.log.error("Exiting!")
    sys.exit(1)


## Get the specified minimizer class.
try:
    MinimizerCls = prof.getMinimizerClass(opts.MINIMIZER, useminos=opts.USEMINOS,
                                          printminuit=opts.PRINTMINUIT)
    prof.log.debug('Using %s as minimizer.' % MinimizerCls.__name__)
except Exception, e:
    prof.log.error("Problem getting minimizer: %s" % e)
    prof.log.error("Exiting...")
    sys.exit(1)


## Read limits file
if opts.LIMITS is not None:
    prof.io.testReadFile(opts.LIMITS)
    limits = prof.ParameterRange.mkFromFile(opts.LIMITS)
    prof.log.debug("Using minimisation limits from %s: %s" % (opts.LIMITS, limits))
else:
    limits = None
    prof.log.debug("Not using minimisation limits.")


## Parse fixed parameter option
fixedparams = None
if opts.FIXEDPARAMETERS is not None:
    fixedparams = prof.ParameterPoint.mkFromString(opts.FIXEDPARAMETERS)

## Parse start point methods
spmethods = opts.STARTPOINTMETHODS.split(',')
manualsp = None
if opts.MANUALSTARTPOINT is not None:
    manualsp = prof.ParameterPoint.mkFromString(opts.MANUALSTARTPOINT)


## Load run combinations
allruns = []
if opts.RUNSFILE:
    prof.log.debug("Using %s as runs file" % opts.RUNSFILE)
    try:
        rcm = prof.RunCombManager.mkFromFile(opts.RUNSFILE)
        allruns = rcm.runcombs
    except Exception, e:
        prof.log.error("Error while opening run combination file %s: %s" % (opts.RUNSFILE, e))
        sys.exit(1)
else:
    prof.log.debug("No run combination file given! Using all available runs.")
    allruns.append(dataproxy.getMCData().availableruns)
prof.log.info("Loaded %i run combinations" % len(allruns))


## Select the observables we want to use for our tune
weights = None
weightsname = None
if opts.OBSERVABLEFILE:
    weightsname = os.path.basename(opts.OBSERVABLEFILE)
    try:
        prof.io.testReadFile(opts.OBSERVABLEFILE)
        weights = prof.WeightManager.mkFromFile(opts.OBSERVABLEFILE)
    except Exception, e:
        prof.log.error("Problem when reading observable file: %s" % e)
        prof.log.error("Exiting!")
        sys.exit(1)
    prof.log.debug("Loaded observable file from %s" % opts.OBSERVABLEFILE)
else:
    weightsname = "unitweights"
    prof.log.debug("No observable file given! Using all available observables.")
    weights = prof.WeightManager()
    for obsname in dataproxy.getMCData().getAvailableObservables():
        weights.addBinRangeWeight(obsname)
prof.log.debug("Loaded observables: %s" % weights)


## Check that all interpolations are available in ipoldir
for runs in allruns:
    path = dataproxy.getIpolFilePath(IpolCls, runs)
    if not os.path.exists(path):
        prof.log.error("Could not find interpolation file for runs %s in"
                       " ipoldir %s: %s" % (sorted(runs), dataproxy.ipolpath, path))
        prof.log.error("Please call prof-interpolate with the correct"
                       " arguments before using this program to build"
                       " interpolation files!")
        prof.log.error("Exiting!")
        sys.exit(1)


## Define goodness of fit class to be used for tuning
# TODO: Be able to choose among different GoFs... load user-specified ones with evalfile?
gofcls = prof.SimpleIpolChi2


def tune(gofobject, spmethod="center"):
    ## TODO: Clean this up: uses lots of undeclared global variables

    ## TODO? Limit tunes to run-specific parameter ranges -- possible with
    ## current data objects?)

    ## Instantiate minimizer
    minimizer = MinimizerCls()
    msg = "Starting minimiser...\n"
    msg += "  using spmethod %s\n" % spmethod
    msg += "  using manualsp %s\n" % manualsp
    msg += "  using limits %s\n" % limits
    msg += "  using fixedpars %s" % fixedparams
    prof.log.debug(msg)

    ## Run minimizer on provided GoF
    result = minimizer.minimize(gofobject,
                                spmethod=spmethod, manualsp=manualsp,
                                limits=limits, fixedpars=fixedparams)
    return result


def mkIpolHistos(result, tundat, outpath):
    prof.log.debug("Writing interpolation histograms to %s" % outpath)
    f = open(outpath, "w")
    f.write('<?xml version="1.0" encoding="ISO-8859-1" ?>\n')
    f.write('<!DOCTYPE aida SYSTEM "http://aida.freehep.org/schemas/3.3/aida.dtd">\n')
    f.write('<aida version="3.3">\n')
    for obs in sorted(tundat.observables):
        f.write(tundat.getInterpolationHisto(obs, result).asAIDA() + "\n\n")
    f.write("</aida>\n")
    f.close()


## Do tuning for each run combination, and append to the ResultList
reslist = prof.ResultList()
reslistfile = os.path.join(TUNEOUTDIR, "results.pkl")
nummins = len(allruns)*len(spmethods)
tunenum = 0
for irun, runs in enumerate(allruns):
    for imeth, spmethod in enumerate(spmethods):
        tunenum += 1
        itune = len(spmethods) * (irun + opts.IRUNOFFSET) + imeth
        itune_name = "tune-%s-%03i" % (weightsname, itune)
        prof.log.info("Starting %i/%i tune, %s..." % (tunenum, nummins, itune_name))

        ## Tune output directory for params and histograms
        ITUNEOUTDIR = os.path.join(TUNEOUTDIR, itune_name)
        prof.io.makeDir(ITUNEOUTDIR)
        if opts.SAVEIPOLHISTOS:
            IPOLHISTOOUTDIR = os.path.join(ITUNEOUTDIR, "ipolhistos")
            prof.log.debug("Using %s for interpolation histo storage" % IPOLHISTOOUTDIR)
            prof.io.makeDir(IPOLHISTOOUTDIR)

        try:
            ## Load interpolation set
            path = dataproxy.getIpolFilePath(IpolCls, runs)
            prof.log.debug("Loading ipolset from %s" % path)
            ipolset = prof.InterpolationSet.mkFromPickle(path)
            prof.log.debug("Loaded interpolation set %s" % (ipolset))
            ipolhistonames = ipolset.getHistogramNames()

            prof.log.debug("Creating TuneData")
            tundat = None
            try:
                tundat = dataproxy.getTuneData(withref=True, useipol=IpolCls,
                                               useobs=weights.observables, useruns=runs)
                tundat.applyObservableWeightDict(weights)
                # TODO: Add "epsilon error" to alleviate these problems.
                tundat.vetoEmptyErrors()
            except AssertionError, e:
                prof.log.error("Could not build tune data from the specified interpolation. Does the ipol object contain all the bins that your tune is asking for?")
                prof.log.debug(e)
                sys.exit(4)

            ## Make GoF object for this ipol and tunedata
            gof = gofcls(tundat)

            ## Make tune
            result = tune(gof, spmethod)
            prof.log.info("\nTune:\n%s\n" % result)
            reslist.append(result)

            ## Get GoF
            gof.setParams(result.values)
            TUNE_GOF = gof.calcGoF()

            ## Computation of actual Delta(GoF) from a relative spec if required
            if opts.EIGENTUNES:
                msg = "Computing eigentunes with Delta(GoF) = %s" % opts.EIGENTUNES_DELTA_GOF
                if opts.EIGENTUNES_DELTA_GOF.endswith("x"):
                    opts.EIGENTUNES_DELTA_GOF = float(opts.EIGENTUNES_DELTA_GOF[:-1]) * TUNE_GOF
                    msg += "%e = %e" % (TUNE_GOF, opts.EIGENTUNES_DELTA_GOF)
                elif opts.EIGENTUNES_DELTA_GOF.endswith("%"):
                    opts.EIGENTUNES_DELTA_GOF = float(opts.EIGENTUNES_DELTA_GOF[:-1]) / 100.0 * TUNE_GOF
                    msg += "of %e = %e" % (TUNE_GOF, opts.EIGENTUNES_DELTA_GOF)
                else:
                    opts.EIGENTUNES_DELTA_GOF = float(opts.EIGENTUNES_DELTA_GOF)
                prof.log.info(msg)

            ## Write out params file for central tune
            if opts.SAVEPARAMS:
                paramsfile = os.path.join(ITUNEOUTDIR, "%s-0.params" % itune_name)
                result.values.writeParamFile(paramsfile)

            ## Store interpolation histograms for central tune
            if opts.SAVEIPOLHISTOS:
                ipolhistofile = os.path.join(IPOLHISTOOUTDIR, "%s-0.aida" % itune_name)
                mkIpolHistos(result, tundat, ipolhistofile)
            else:
                prof.log.debug("Not storing any histogram data for later plotting.")

            ## Write out tune pickle file
            import pickle
            onereslist = prof.ResultList([result])
            f = open(os.path.join(ITUNEOUTDIR, "%s-0.pkl" % itune_name), "w")
            pickle.dump(onereslist, f)
            f.close()


            ## EIGENTUNES
            ## Create variations on optimal result vector by going in the 2N +- principle direction vectors
            if opts.EIGENTUNES:
                prof.log.info("Eigentunes:")
                import numpy
                from professor.tools import eigen

                def mkDeltaTune(result, i, scale):
                    covmat = result.covariance
                    T_transp, S, T = eigen.eigenDecomposition(covmat)
                    delta = scale * numpy.sqrt(S[i])
                    eigenbasis_unitvec = list(numpy.zeros(len(result.values)))
                    eigenbasis_unitvec[i] = 1
                    eigenbasis_vec = delta * numpy.matrix(eigenbasis_unitvec)
                    result_params_trf = (T_transp * numpy.matrix(result.values).transpose()).transpose()
                    etune_params_trf = result_params_trf + eigenbasis_vec
                    etune_params_t = T * etune_params_trf.transpose()
                    etune_params = numpy.array(etune_params_t.transpose().tolist()[0])
                    etune_unscaled = prof.ParameterTune(result.values.keys(), etune_params, runs=runs, obs=weights.observables)
                    return S[i], etune_unscaled

                def mkDeltaTuneAndGoF(result, i, scale):
                    mys, mytune = mkDeltaTune(result, i, scale)
                    gof.setParams(mytune)
                    return mys, mytune, gof.calcGoF()


                for i in xrange(len(result.values)):

                    ## Find Delta(GoF) point explicitly -- the 1-sigma eigenvectors from Minuit seem far too big
                    def delta_gof_with_offset(nsigma):
                        global result, i, TUNE_GOF, opts
                        mys, mytune, mygof = mkDeltaTuneAndGoF(result, i, nsigma)
                        # print nsigma, mygof
                        return mygof - TUNE_GOF - opts.EIGENTUNES_DELTA_GOF

                    def find_delta_gof_offset_dsigma(tune_name, maxattempts=10):
                        global opts, i, result
                        import scipy.optimize
                        dnsig_inner = 0
                        dnsig_outer = opts.EIGENTUNES_DELTA_GOF + 1
                        for attempt in xrange(1, maxattempts+1):
                            prof.log.debug("%s: attempt #%d to find dGoF = %f from GoF = %f. |dsigma| = %f" %
                                          (tune_name, attempt, opts.EIGENTUNES_DELTA_GOF, TUNE_GOF, dnsig_outer))
                            try:
                                if "+" in tune_name:
                                    assert(delta_gof_with_offset(dnsig_inner) < 0)
                                    nsig_dtune = scipy.optimize.brentq(delta_gof_with_offset, dnsig_inner, dnsig_outer)
                                elif "-" in tune_name:
                                    assert(delta_gof_with_offset(-dnsig_inner) < 0)
                                    nsig_dtune = scipy.optimize.brentq(delta_gof_with_offset, -dnsig_outer, -dnsig_inner)
                                else:
                                    raise Exception("Eigentune names must contain a + or - sign to denote the direction of deviation")
                                lambda_i, dtune, gof_dtune = mkDeltaTuneAndGoF(result, i, nsig_dtune)
                                prof.log.info("%s: (Delta(sigma) = %e, GoF = %e)\n%s\n" % (tune_name, nsig_dtune, gof_dtune, dtune))
                                return nsig_dtune, gof_dtune, dtune, lambda_i
                            except ValueError:
                                dnsig_inner = dnsig_outer
                                dnsig_outer *= 2
                                if maxattempts and attempt == maxattempts:
                                    raise Exception("No %s eigentune could be constructed for Delta(GoF) = %f" %
                                                    (tune_name, opts.EIGENTUNES_DELTA_GOF))

                    def process_dtune(tune_name):
                        try:
                            nsig_dtune, gof_dtune, tune_dtune, lambda_i = find_delta_gof_offset_dsigma(tune_name)
                            ## Store params files for error tunes
                            if opts.SAVEPARAMS:
                                paramsfile_dtune = os.path.join(ITUNEOUTDIR, "%s-%s.params" % (itune_name, tune_name))
                                result.values.writeParamFile(paramsfile_dtune)
                            ## Store interpolation histograms for error tunes
                            if opts.SAVEIPOLHISTOS:
                                ipolhistofile_dtune = os.path.join(IPOLHISTOOUTDIR, "%s-%s.aida" % (itune_name, tune_name))
                                mkIpolHistos(tune_dtune, tundat, ipolhistofile_dtune)
                            # ## Write out eigentune pickle file
                            # TODO: Make sure that the eigentune "result" object that's stored has the right params ("values") set
                            # import pickle
                            # f = open(os.path.join(ITUNEOUTDIR, "%s-%s.pkl" % (itune_name, tune_name)), "w")
                            # pickle.dump(result, f)
                            # f.close()

                        except Exception, e:
                            prof.log.warning(e)

                    ## Make and process the eigentunes
                    tune_plus_name = "%02d+" % (i+1)
                    process_dtune(tune_plus_name)
                    tune_minus_name = "%02d-" % (i+1)
                    process_dtune(tune_minus_name)

                    # TODO: Include error tunes in some ResultCollectionList-type object for pickling

                    # import numpy
                    # for s in numpy.linspace(-1.1, 1.1, num=23):
                    #     mys, mytune, mygof = mkDeltaTuneAndGoF(result, i, s)
                    #     gof.setParams(mytune)
                    #     print s, mygof


        except prof.MinimizerError, err:
            prof.log.error("Minimizer error for this tuning attempt: %s" % err)
            prof.log.error("No result is saved!")
            continue
        except IOError, ioe:
            prof.log.error("Error when retrieving interpolation: %s" %ioe)
            prof.log.error("No result computed.")
            continue
        except KeyboardInterrupt:
            prof.log.critical("Keyboard interrupt detected, you'll have to "
                              "make do with only %i results." % len(reslist))
            break
        if RECVD_KILL_SIGNAL is not None:
            prof.log.critical("Leaving loop early due to signal %s: you'll "
                              "have to make do with only %i results." %
                              (RECVD_KILL_SIGNAL, len(reslist)))
            break
        ## Write results snapshot
        prof.log.debug("Writing %i results snapshots in %s" % (len(reslist), reslistfile))
        reslist.write(reslistfile)
    if RECVD_KILL_SIGNAL is not None:
        break

## Pickle the final list of all tune results
prof.log.debug("Writing results to %s" % reslistfile)
reslist.write(reslistfile)
