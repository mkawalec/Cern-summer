Professor TODO
--------------

For 1.1.0:

* Sphinx docs: envelopes, correlation colour maps... specifically these:
    - prof-checkspace
    - prof-compare-tunes
    - prof-envelopes
    - prof-ipolhistos
    - prof-lsobs
    - prof-plotcorrelations
    - prof-plotpulls
    - prof-showipol
    - prof-showminresults
    - prof-terror

* Develop a method to deal with +/- asymmetries and differences between
  eigenvectors for n_sigma ~> 1 in eigentunes (does minuit calc for n_sigma ~
  epsilon?)

* Use WeightManager for "epsilon" errors... multiply on MC or ref error? Needs to
  be optional, and I think should also be overrideable by a single global
  epsilon factor specified in the scripts, so that users don't have to make the
  epsilon weights file if they don't want to use it for anything non-trivial. => ANDY

* Command line interface re-working. Too many scripts have a million options for
  every different plot style choice: that won't work, we need to pick a sensible
  default and let users modify the script or output if they want something
  specific. In particular, I don't think we really need/want a --no-foo option
  for every --foo option.

* Add the LEP tune comparison plots to the Prof plot gallery. => HENDRIK

* Higher-order polynomials: 4th and 5th order for more generic parameterisation
  tasks. Probably requires splitting professor.interpolation.interpolation module.

* Diversify from the SVD mechanism for ipol generation. Neural networks are
  quite promising: we can use e.g. the PyROOT interface to TMVA, and this would
  give a more parameterisation-free result. Might be slower, and won't be as
  deterministic, but it would be a powerful extra feature. => ANDY

* Think about generalising the weights file to allow more things than just
  weights to be specified: the value could be a dict to also use different
  parameterisations for different histos/regions. In this model, the epsilon
  errors and so-on would also live in this one file rather than a separate one
  with the scalar format used for weights.

* Boundary sampling: generate samplings on the walls and corners of the space to
  constrain away parameterisation deviations outside the sampled region. We
  would need to keep these runs separate, so that they could all be used in all
  ipol buildings, with the runcomb sampling only happening to the "bulk" points.

* Parameterising the MC errors? Any use-case or does the median anchor point
  error do a good enough job?

* Can we now remove the matplotlib "memory leak avoidance" hacks? By requiring a
  higher version of matplotlib perhaps? => ???

* Make API more pleasant... focus on consistency, removing aliases/synonyms,
  dropping "get" prefixes, and making the names snappier. => ANDY

* Document reducing a runcombs list to one which only corresponds to
  runs within a more restricted params range (with some warnings if it suspects
  that the ranges are actually being enlarged)::

      prof-runcombs extract all.run.combinations --ranges narrow.range --mc mc/
      prof-runcombs extract results.pkl --ranges narrow.range --mc mc/

* Use new style string formatting and "with ... as foo:" file handling: requires
  Python >= what version? Use from __future__ import ... mechanism or require
  Python 2.6... I guess the former for now.

* Clean ResultList interface.

* Modify prof-plotpulls to plot observable comparison plots comparing ipols to
  anchor points, as a way of checking ipol performance without having to do new
  line scans.

* Finish error bands study! 3-param JIMMY tune -> 100 "stat" smearings around
  each of 100 "sys" minimisation points, using many different interpolations.

* WeightManager should provide a wm.getValue("/path/to/MYHIST:42") if at all possible.

* Provide more structured histo loading from multiple formats via functions in
  a professor.histo.input module.

* Use clearer vetoing for inputs to prof-sensitivities: should we exclude bins
  with few stats or leave that up to the user via the prof-sensitivities interface?

* Bin-bin correlations: correlations between bins within an observable will
  influence the GoF, but we don't know exactly how. We suspect some effect on
  the error2 calc, i.e. bin_i.err**2 -> bin_i.err * bin_j.err or similar. But
  how does this affect the number of DoF? Presumably correlations mean that
  there are not the number of independent DoF weights that we were previously
  assuming. And how do bin weights enter if weight_i != weight_j? All stuff for
  the MSc student to think about!

  What we do NOW is to add an observable-level hook to DataProxy to provide the
  correlation matrix, i.e. dp.getCorrelationMatrix("path/to/MYOBS"), which
  should currently return an identity matrix of the correct size (i.e. #bins)
  for that observable. Maybe we could try updating the chi2 to use it. We should
  check whether this is going to slow down chi2 computation significantly: it's
  a borderline use-case, and maybe it's better to return None for the 99% of
  cases where there is no corr matrix and put a corresponding conditional in the
  chi2/DoF calcs. OR, also have a dp.hasCorrelationMatrix(obspath) function so
  that the chi2 calc can *choose* to be more efficient... I think I like that
  best.

  Update: I've been thinking about this a bit... the number of true DoF can be
  calculated iteratively from a bin-by-bin correlation matrix
  (db_i/dx)/(db_j/dx) * b_j/b_i for a "hidden parameter" x by starting from the
  assumption that all bins are independent and "worth" a whole unit of DoF, then
  stripping the dependency on each other parameter. Quite neat, not sure if it's
  standard or if there is a closed-form equivalent. Anyway, the effect would
  just be to reduce the DoF... whether the weighting should be changed across
  the histo I don't know... need to think about that.

* Try using GPU computation for parallelising the bin ipol building or
  multi-ipol minimising on a single machine. PyCUDA seems a very impressive
  package. This would be a nice MSc or summer student project.

* Logging to use colourising (in place of INFO, DEBUG etc. markers) if scripts
  are run interactively (sys.stdout.isatty() == True)
  http://stackoverflow.com/questions/384076/how-can-i-make-the-python-logging-output-to-be-colored
