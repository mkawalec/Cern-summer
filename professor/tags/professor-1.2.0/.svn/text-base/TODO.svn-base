Professor TODO
==============

For 1.3.0:
----------

* Write TeX parser to sanitize TeX -> text strings, e.g. getting rid of markup like \,, \mathrm, \text, etc.

* Sphinx docs: envelopes, correlation colour maps... specifically these:
    - prof-checkspace
    - prof-compare-tunes
    - prof-envelopes
    - prof-ipolhistos
    - prof-lsobs
    - prof-plotcorrelations
    - prof-plotpulls
    - prof-showipol
    - prof-showminresults
    - prof-terror

* Common script options documented in one place only.

* Reinstate --limits to auto-detect the param limits of the sample points which
  were actually used for that parameterisation. Store this info on the
  ipol object (along with the min and max of each bin -- see below).

* prof-I: display a background envelope calculated from the anchor points. Are
  the max and min stored in the bin ipol object? We should do so.

* Use WeightManager for "epsilon" errors... multiply on MC or ref error? Needs to
  be optional, and I think should also be overrideable by a single global
  epsilon factor specified in the scripts, so that users don't have to make the
  epsilon weights file if they don't want to use it for anything non-trivial. => ANDY

* Command line interface re-working. Too many scripts have a million options for
  every different plot style choice: that won't work, we need to pick a sensible
  default and let users modify the script or output if they want something
  specific. In particular, I don't think we really need/want a --no-foo option
  for every --foo option.

* Make API more pleasant... focus on consistency, removing aliases/synonyms,
  dropping "get" prefixes, and making the names snappier. => ANDY

* Catch any exceptions that we find while using Professor: the command line
  should *never* produce a user-visible exception traceback.


For 1.4.0:
----------

* Higher-order polynomials: provide 4th and 5th order for more generic
  parameterisation tasks. Probably requires splitting
  professor.interpolation.interpolation module, which is already too large.

* --eigentunes-dgof should accept either a fixed delta or a %/x of GoF_min.

* Check Python 2to3 compatibility.

* Finish error bands study! 3-param JIMMY tune -> 100 "stat" smearings around
  each of 100 "sys" minimisation points, using many different interpolations.

* WeightManager should provide a wm.getValue("/path/to/MYHIST:42") if at all possible.

* Provide more structured histo loading from multiple formats via functions in
  a professor.histo.input module.



For release after that:
-----------------------

* Parameterising the MC errors? Any use-case or does the median anchor point
  error do a good enough job?

* Develop a method to deal with +/- asymmetries and differences between
  eigenvectors for n_sigma ~> 1 in eigentunes (does minuit calc for n_sigma ~
  epsilon?)

* Diversify from the SVD mechanism for ipol generation. Neural networks are
  quite promising: we can use e.g. the PyROOT interface to TMVA, and this would
  give a more parameterisation-free result. Might be slower, and won't be as
  deterministic, but it would be a powerful extra feature. => ANDY

* Think about generalising the weights file to allow more things than just
  weights to be specified: the value could be a dict to also use different
  parameterisations for different histos/regions. In this model, the epsilon
  errors and so-on would also live in this one file rather than a separate one
  with the scalar format used for weights.

* Boundary sampling: generate samplings on the walls and corners of the space to
  constrain away parameterisation deviations outside the sampled region. We
  would need to keep these runs separate, so that they could all be used in all
  ipol buildings, with the runcomb sampling only happening to the "bulk" points.

* Use new style string formatting and "with ... as foo:" file handling: requires
  Python >= what version? Use from __future__ import ... mechanism or require
  Python 2.6... I guess the former for now.

* Clean ResultList interface.

* Modify prof-plotpulls to plot observable comparison plots comparing ipols to
  anchor points, as a way of checking ipol performance without having to do new
  line scans.

* Use clearer vetoing for inputs to prof-sensitivities: should we exclude bins
  with few stats or leave that up to the user via the prof-sensitivities interface?

* Bin-bin correlations: correlations between bins within an observable will
  influence the GoF, but we don't know exactly how. We suspect some effect on
  the error2 calc, i.e. bin_i.err**2 -> bin_i.err * bin_j.err or similar. But
  how does this affect the number of DoF? Presumably correlations mean that
  there are not the number of independent DoF weights that we were previously
  assuming. And how do bin weights enter if weight_i != weight_j? All stuff for
  the MSc student to think about!

  What we do NOW is to add an observable-level hook to DataProxy to provide the
  correlation matrix, i.e. dp.getCorrelationMatrix("path/to/MYOBS"), which
  should currently return an identity matrix of the correct size (i.e. #bins)
  for that observable. Maybe we could try updating the chi2 to use it. We should
  check whether this is going to slow down chi2 computation significantly: it's
  a borderline use-case, and maybe it's better to return None for the 99% of
  cases where there is no corr matrix and put a corresponding conditional in the
  chi2/DoF calcs. OR, also have a dp.hasCorrelationMatrix(obspath) function so
  that the chi2 calc can *choose* to be more efficient... I think I like that
  best.

  Update: I've been thinking about this a bit... the number of true DoF can be
  calculated iteratively from a bin-by-bin correlation matrix
  (db_i/dx)/(db_j/dx) * b_j/b_i for a "hidden parameter" x by starting from the
  assumption that all bins are independent and "worth" a whole unit of DoF, then
  stripping the dependency on each other parameter. Quite neat, not sure if it's
  standard or if there is a closed-form equivalent. Anyway, the effect would
  just be to reduce the DoF... whether the weighting should be changed across
  the histo I don't know... need to think about that.

* Try using GPU computation for parallelising the bin ipol building or
  multi-ipol minimising on a single machine. PyCUDA seems a very impressive
  package. This would be a nice MSc or summer student project.

* prof-plotpulls: have a Latex-string sanitizing method and/or write output suitable for
  make-plots, also, there seems to be a memory issue with this script
